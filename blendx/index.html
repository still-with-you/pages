<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <meta name="title" content="BlendX: Complex Multi-Intent Detection with Blended Patterns - Yoon et al.">
  <meta name="description" content="BlendX is a multi-intent detection dataset suite with diverse blended patterns and new complexity metrics for task-oriented dialogue.">
  <meta name="keywords" content="multi-intent detection, task-oriented dialogue, dataset, BlendX, LREC-COLING 2024, conversational AI">
  <meta name="author" content="Yejin Yoon, Jungyeon Lee, Kangsan Kim, Chanhee Park, Taeuk Kim">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <meta property="og:site_name" content="HYU-NLP Lab">
  <meta property="og:title" content="BlendX: Complex Multi-Intent Detection with Blended Patterns">
  <meta property="og:description" content="BlendX is a multi-intent detection dataset suite with diverse blended patterns and new complexity metrics for task-oriented dialogue.">
  <meta property="og:url" content="https://still-with-you.github.io/pages/blendx/">
  <meta property="og:image" content="https://still-with-you.github.io/pages/blendx/static/images/blendx_overview.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="BlendX overview figure">
  <meta property="article:published_time" content="2024-05-01T00:00:00.000Z">
  <meta property="article:author" content="Yejin Yoon">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="multi-intent detection">
  <meta property="article:tag" content="dataset">

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="BlendX: Complex Multi-Intent Detection with Blended Patterns">
  <meta name="twitter:description" content="BlendX is a multi-intent detection dataset suite with diverse blended patterns and new complexity metrics for task-oriented dialogue.">
  <meta name="twitter:image" content="https://still-with-you.github.io/pages/blendx/static/images/blendx_overview.png">
  <meta name="twitter:image:alt" content="BlendX overview figure">

  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="BlendX: Complex Multi-Intent Detection with Blended Patterns">
  <meta name="citation_author" content="Yoon, Yejin">
  <meta name="citation_author" content="Lee, Jungyeon">
  <meta name="citation_author" content="Kim, Kangsan">
  <meta name="citation_author" content="Park, Chanhee">
  <meta name="citation_author" content="Kim, Taeuk">
  <meta name="citation_publication_date" content="2024">
  <meta name="citation_conference_title" content="LREC-COLING 2024">
  <meta name="citation_pdf_url" content="https://aclanthology.org/2024.lrec-main.218.pdf">
  
  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  
  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">


  <title>BlendX: Complex Multi-Intent Detection with Blended Patterns</title>
  
  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/png" href="static/images/favicon.png">
  <link rel="apple-touch-icon" href="static/images/apple-touch-icon.png">
  
  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="../static/css/bulma.min.css">
  <link rel="stylesheet" href="../static/css/index.css">
  
  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="../static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="../static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="../static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  
  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="../static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="../static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="../static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  
  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="../static/js/fontawesome.all.min.js"></script>
  <script defer src="../static/js/bulma-carousel.min.js"></script>
  <script defer src="../static/js/bulma-slider.min.js"></script>
  <script defer src="../static/js/index.js"></script>
  
  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "BlendX: Complex Multi-Intent Detection with Blended Patterns",
    "description": "BlendX is a multi-intent detection dataset suite with diverse blended patterns and new complexity metrics for task-oriented dialogue.",
    "author": [
      {
        "@type": "Person",
        "name": "Yejin Yoon",
        "affiliation": {
          "@type": "Organization",
          "name": "HYU-NLP Lab"
        }
      },
      {
        "@type": "Person",
        "name": "Jungyeon Lee",
        "affiliation": {
          "@type": "Organization",
          "name": "HYU-NLP Lab"
        }
      },
      {
        "@type": "Person",
        "name": "Kangsan Kim",
        "affiliation": {
          "@type": "Organization",
          "name": "HYU-NLP Lab"
        }
      },
      {
        "@type": "Person",
        "name": "Chanhee Park",
        "affiliation": {
          "@type": "Organization",
          "name": "HYU-NLP Lab"
        }
      },
      {
        "@type": "Person",
        "name": "Taeuk Kim",
        "affiliation": {
          "@type": "Organization",
          "name": "HYU-NLP Lab"
        }
      }
    ],
    "datePublished": "2024-05-01",
    "publisher": {
      "@type": "Organization",
      "name": "LREC-COLING 2024"
    },
    "url": "https://still-with-you.github.io/pages/blendx/",
    "image": "https://still-with-you.github.io/pages/blendx/static/images/blendx_overview.png",
    "keywords": ["multi-intent detection", "task-oriented dialogue", "dataset", "BlendX", "LREC-COLING"],
    "abstract": "Task-oriented dialogue systems often assume a single intent per utterance, but real users express multiple intents. BlendX is a suite of refined multi-intent detection datasets with diverse blended patterns built via rule-based heuristics and ChatGPT-assisted generation with similarity-driven selection. We introduce three metrics capturing word count, conjunction use, and pronoun usage to quantify complexity, and experiments show strong models struggle on BlendX, highlighting gaps in current MID methods.",
    "citation": "Yoon et al. 2024. BlendX: Complex Multi-Intent Detection with Blended Patterns.",
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://still-with-you.github.io/pages/blendx/"
    },
    "about": [
      {
        "@type": "Thing",
        "name": "multi-intent detection"
      },
      {
        "@type": "Thing",
        "name": "task-oriented dialogue"
      },
      {
        "@type": "Thing",
        "name": "datasets"
      }
    ]
  }
  </script>
  
  <!-- Website/Organization Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "HYU-NLP Lab",
    "url": "https://github.com/HYU-NLP",
    "logo": "https://still-with-you.github.io/pages/blendx/static/images/favicon.ico",
    "sameAs": [
      "https://github.com/HYU-NLP"
    ]
  }
  </script>
</head>
<body>


  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>

  <main id="main-content">
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-2 publication-title">
              <span class="title-line title-line-primary">BlendX:</span>
              <span class="title-line">Complex Multi-Intent Detection with Blended Patterns</span>
            </h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://still-with-you.github.io/" target="_blank">Yejin Yoon</a>,</span>
              <span class="author-block">Jungyeon Lee,</span>
              <span class="author-block">Kangsan Kim,</span>
              <span class="author-block">Chanhee Park,</span>
              <span class="author-block">
                <a href="https://galsang.github.io/" target="_blank">Taeuk Kim</a>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><a href="https://sites.google.com/view/hyu-nlp/" target="_blank">Hanyang University</a></span>
              <span class="author-block conference-line"><br>LREC-COLING 2024</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <div class="link-row">
                  <span class="link-block">
                    <a href="https://aclanthology.org/2024.lrec-main.218/" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>ACL Anthology</span>
                    </a>
                  </span>

                  <span class="link-block">
                    <a href="https://arxiv.org/abs/2403.18277" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="ai ai-arxiv"></i>
                      </span>
                      <span>arXiv</span>
                    </a>
                  </span>

                  <span class="link-block">
                    <a href="https://github.com/HYU-NLP/BlendX" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fab fa-github"></i>
                      </span>
                      <span>Code</span>
                    </a>
                  </span>

                  <span class="link-block">
                    <a href="https://huggingface.co/datasets/HYU-NLP/BlendX" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-database"></i>
                      </span>
                      <span>Dataset</span>
                    </a>
                  </span>

                  <span class="link-block">
                    <a href="static/pdfs/blendx-slides.pdf" target="_blank"
                    class="external-link button is-normal is-rounded is-muted">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Slides</span>
                    </a>
                  </span>

                  <span class="link-block">
                    <a href="static/pdfs/blendx-poster.pdf" target="_blank"
                    class="external-link button is-normal is-rounded is-muted">
                      <span class="icon">
                        <i class="fas fa-image"></i>
                      </span>
                      <span>Poster</span>
                    </a>
                  </span>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
  </div>
</section>


<!-- Teaser image -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <figure class="image">
        <img src="static/images/blendx_overview.png" alt="BlendX overview figure" loading="lazy">
      </figure>
      <h2 class="subtitle has-text-centered">
        Overview of the BlendX construction framework across ATIS, Banking77, CLINC150, and SNIPS.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser image -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Task-oriented dialogue (TOD) systems often assume a single intent per utterance, but real users frequently express multiple intents. BlendX is a suite of refined multi-intent detection datasets with diverse blended patterns built via rule-based heuristics and ChatGPT-assisted generation with similarity-driven selection. We introduce three metrics that quantify utterance complexity using word count, conjunction use, and pronoun usage. Experiments show that strong MID models still struggle on BlendX, highlighting the need to revisit current multi-intent detection methods.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Narrative -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths content overview-content">
        <h2 class="title is-3 overview-title">Overview</h2>

        <h3 class="title is-4">Motivation</h3>
        <p>
          Multi-intent detection (MID) is central to realistic task-oriented dialogue, yet many datasets still assume a single intent per utterance. Existing in-domain datasets such as MixATIS and MixSNIPS capture limited blending patterns and under-represent harder, naturally mixed requests.
        </p>

        <h3 class="title is-4">Dataset Construction</h3>
        <p>
          BlendX is built from ATIS, Banking77, CLINC150, and SNIPS. Single-intent utterances are blended using both manual rules and ChatGPT-assisted generation with similarity-based selection. The resulting datasets expand the space of blended patterns while keeping sources separate to preserve domain consistency.
        </p>
        <figure class="figure-card section-figure full-width">
          <img src="static/images/blendx_overview.png" alt="BlendX construction overview" loading="lazy">
          <figcaption>Figure 1. BlendX construction pipeline and blended pattern coverage.</figcaption>
        </figure>

        <h3 class="title is-4">Evaluation</h3>
        <p>
          We introduce three metrics that quantify complexity in blended utterances: word count, conjunction usage, and pronoun usage. Benchmarking strong MID models shows sizeable drops on BlendX, highlighting the need for models that handle richer compositional intent patterns.
        </p>

        <h3 class="title is-4">Resources</h3>
        <p>
          BlendX and MixX (v1.0 English) along with KoBlendX and KoMixX (v2.0 Korean) are available via the repository and Hugging Face dataset hub.
        </p>
      </div>
    </div>
  </div>
</section>
<!-- End narrative -->



<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <div class="bibtex-header">
        <h2 class="title">BibTeX</h2>
        <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
          <i class="fas fa-copy"></i>
          <span class="copy-text">Copy</span>
        </button>
      </div>
      <pre id="bibtex-code"><code>@inproceedings{yoon-etal-2024-blendx-complex,
  title = "{B}lend{X}: Complex Multi-Intent Detection with Blended Patterns",
  author = "Yoon, Yejin  and
    Lee, Jungyeon  and
    Kim, Kangsan  and
    Park, Chanhee  and
    Kim, Taeuk",
  editor = "Calzolari, Nicoletta  and
    Kan, Min-Yen  and
    Hoste, Veronique  and
    Lenci, Alessandro  and
    Sakti, Sakriani  and
    Xue, Nianwen",
  booktitle = "Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",
  month = may,
  year = "2024",
  address = "Torino, Italia",
  publisher = "ELRA and ICCL",
  url = "https://aclanthology.org/2024.lrec-main.218",
  pages = "2428--2439"
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            Built with the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> (adapted from <a href="https://nerfies.github.io" target="_blank">Nerfies</a>).
            Licensed under <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">CC BY-SA 4.0</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
